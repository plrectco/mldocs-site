{
    "docs": [
        {
            "location": "/", 
            "text": "Welcome to Machine Learning\n\n\nThis website is created for the machine learning project doc demo of Wang's Lab. Rights reserved.", 
            "title": "Home"
        }, 
        {
            "location": "/#welcome-to-machine-learning", 
            "text": "This website is created for the machine learning project doc demo of Wang's Lab. Rights reserved.", 
            "title": "Welcome to Machine Learning"
        }, 
        {
            "location": "/db/mysql/", 
            "text": "", 
            "title": "Relational Database"
        }, 
        {
            "location": "/db/mongo/", 
            "text": "MongoDB-Python Driver\n\n\nSample code:\n\n\n\n\nNotice: The interaction between the MongoDB database and Tensorflow is done through the \nnumpy.array()\n. Since the interaction is specific to each situation, the following is just one sample code.\n\n\n\n\nimport tensorflow as tf\nimport numpy as np\nfrom pymongo import MongoClient\n\ndef initialize_db_col(database, col):\n    client      = MongoClient()\n\n    # Access the target database and corresponding collection\n    db          = client[database]\n    collection  = db[col]\n\n    return collection\n\ndef mongodb_to_tensorflow(collection, field):\n    # REQUIRE: The target datasets must be imported into the database\n\n    # Fetch the key list in the database\n    attr        = [\nsepal_length\n, \nsepal_width\n, \npetal_length\n, \npetal_width\n, \nlabel\n]\n\n    # sample      = collection.find_one()\n    # attr_cnt    = len(sample) - 1           # number of attributes\n    # entry_cnt   = collection.count()        # number of entries\n\n    num_arr     = get_numpy_array(collection, attr, field)\n    return num_arr\n\ndef tensorflow_to_mongodb(collection, entry):\n    # Insert one entry into the collection\n    collection.insert_one(entry)\n\ndef get_numpy_array(collection, attr, field):\n    data = []\n    for entry in collection.find():\n        l = []\n        for i in field:\n            l.append(entry[attr[i]])\n        data.append(l)\n    return np.array(data)\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n\n# train data\n\nfield       = (0,1,2,3)\nlabel       = (4,)\ndatabase    = \ntrain\n\ncol         = \ncol\n\n# Initialize the database and the collection\ncollection  = initialize_db_col(database, col)\n# read the first 4 columns\nx_data      = mongodb_to_tensorflow(collection, field)\n# read the fifth column\ntarget      = mongodb_to_tensorflow(collection, label)\n\ny_data = np.zeros((len(target),3))\n\nfor i in list(range(0, len(y_data), 1)):\n    map = {\n        0: [1, 0, 0],\n        1: [0, 1, 0],\n        2: [0, 0, 1],\n    }\n    y_data[i] = map[target[i][0]]\n\n\n# print(y_data.shape)\n# set placeholder to receive data\n# define placeholder for inputs to network  \nxs = tf.placeholder(tf.float32, [None, 4])\nys = tf.placeholder(tf.float32, [None, 3])\n\n# define the layers\n# add hidden layer inpuy : xs 12unit   \nl1          = add_layer(xs, 4, 12, activation_function=tf.nn.relu)\n# add output layer input: l1  output  3 classes\nprediction1 = add_layer(l1, 12, 3, activation_function=None)\n# add softmax layer\nprediction  = tf.nn.softmax(prediction1)\n\n\n# define loss\n# the error between prediciton and real data    \nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                                              reduction_indices=[1]))\n\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))\n\n\n# choose optimizer     \ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n\n\n# important step, initial\ninit = tf.global_variables_initializer()  # new feature\nsess = tf.Session()\n# run\nsess.run(init)\n\n# sess.run optimizer\n# Initialize the output database and the collection\ndatabase    = \ntrain_result\n\ncol         = \nbp_iris\n\ncollection  = initialize_db_col(database, col)\nfor i in range(5000):\n    # training train_step \n loss , placeholder ,feed give data\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 20 == 0:\n        # to see the step improvement\n        # print(sess.run(cross_entropy, feed_dict={xs: x_data, ys: y_data}))\n        entry       = {}\n        entry[str(i)]    = str(sess.run(cross_entropy, feed_dict={xs: x_data, ys: y_data}))\n        tensorflow_to_mongodb(collection, entry)\n\n# Finish Indicator\nprint(\nTraining Results of BP Algorithm with Iris Datasets have been inserted into the database!\n)\n\n\n\n\nReference:\n\n\n\n\nBasic tutorial: http://www.runoob.com/mongodb/mongodb-tutorial.html\n\n\nOfficial documentation: https://docs.mongodb.com/manual/\n\n\nMongoDB-Python Driver: http://api.mongodb.com/python/current/tutorial.html?_ga=1.126571278.205344545.1483513991#tutorial", 
            "title": "Non-relational Database"
        }, 
        {
            "location": "/db/mongo/#mongodb-python-driver", 
            "text": "", 
            "title": "MongoDB-Python Driver"
        }, 
        {
            "location": "/db/mongo/#sample-code", 
            "text": "Notice: The interaction between the MongoDB database and Tensorflow is done through the  numpy.array() . Since the interaction is specific to each situation, the following is just one sample code.   import tensorflow as tf\nimport numpy as np\nfrom pymongo import MongoClient\n\ndef initialize_db_col(database, col):\n    client      = MongoClient()\n\n    # Access the target database and corresponding collection\n    db          = client[database]\n    collection  = db[col]\n\n    return collection\n\ndef mongodb_to_tensorflow(collection, field):\n    # REQUIRE: The target datasets must be imported into the database\n\n    # Fetch the key list in the database\n    attr        = [ sepal_length ,  sepal_width ,  petal_length ,  petal_width ,  label ]\n\n    # sample      = collection.find_one()\n    # attr_cnt    = len(sample) - 1           # number of attributes\n    # entry_cnt   = collection.count()        # number of entries\n\n    num_arr     = get_numpy_array(collection, attr, field)\n    return num_arr\n\ndef tensorflow_to_mongodb(collection, entry):\n    # Insert one entry into the collection\n    collection.insert_one(entry)\n\ndef get_numpy_array(collection, attr, field):\n    data = []\n    for entry in collection.find():\n        l = []\n        for i in field:\n            l.append(entry[attr[i]])\n        data.append(l)\n    return np.array(data)\n\ndef add_layer(inputs, in_size, out_size, activation_function=None):\n    # add one more layer and return the output of this layer\n    Weights = tf.Variable(tf.random_normal([in_size, out_size]))\n    biases = tf.Variable(tf.zeros([1, out_size]) + 0.1)\n    Wx_plus_b = tf.matmul(inputs, Weights) + biases\n    if activation_function is None:\n        outputs = Wx_plus_b\n    else:\n        outputs = activation_function(Wx_plus_b)\n    return outputs\n\n\n# train data\n\nfield       = (0,1,2,3)\nlabel       = (4,)\ndatabase    =  train \ncol         =  col \n# Initialize the database and the collection\ncollection  = initialize_db_col(database, col)\n# read the first 4 columns\nx_data      = mongodb_to_tensorflow(collection, field)\n# read the fifth column\ntarget      = mongodb_to_tensorflow(collection, label)\n\ny_data = np.zeros((len(target),3))\n\nfor i in list(range(0, len(y_data), 1)):\n    map = {\n        0: [1, 0, 0],\n        1: [0, 1, 0],\n        2: [0, 0, 1],\n    }\n    y_data[i] = map[target[i][0]]\n\n\n# print(y_data.shape)\n# set placeholder to receive data\n# define placeholder for inputs to network  \nxs = tf.placeholder(tf.float32, [None, 4])\nys = tf.placeholder(tf.float32, [None, 3])\n\n# define the layers\n# add hidden layer inpuy : xs 12unit   \nl1          = add_layer(xs, 4, 12, activation_function=tf.nn.relu)\n# add output layer input: l1  output  3 classes\nprediction1 = add_layer(l1, 12, 3, activation_function=None)\n# add softmax layer\nprediction  = tf.nn.softmax(prediction1)\n\n\n# define loss\n# the error between prediciton and real data    \nloss = tf.reduce_mean(tf.reduce_sum(tf.square(ys - prediction),\n                                              reduction_indices=[1]))\n\ncross_entropy = tf.reduce_mean(-tf.reduce_sum(ys * tf.log(prediction),\n                                              reduction_indices=[1]))\n\n\n# choose optimizer     \ntrain_step = tf.train.GradientDescentOptimizer(0.1).minimize(cross_entropy)\n\n\n# important step, initial\ninit = tf.global_variables_initializer()  # new feature\nsess = tf.Session()\n# run\nsess.run(init)\n\n# sess.run optimizer\n# Initialize the output database and the collection\ndatabase    =  train_result \ncol         =  bp_iris \ncollection  = initialize_db_col(database, col)\nfor i in range(5000):\n    # training train_step   loss , placeholder ,feed give data\n    sess.run(train_step, feed_dict={xs: x_data, ys: y_data})\n    if i % 20 == 0:\n        # to see the step improvement\n        # print(sess.run(cross_entropy, feed_dict={xs: x_data, ys: y_data}))\n        entry       = {}\n        entry[str(i)]    = str(sess.run(cross_entropy, feed_dict={xs: x_data, ys: y_data}))\n        tensorflow_to_mongodb(collection, entry)\n\n# Finish Indicator\nprint( Training Results of BP Algorithm with Iris Datasets have been inserted into the database! )", 
            "title": "Sample code:"
        }, 
        {
            "location": "/db/mongo/#reference", 
            "text": "Basic tutorial: http://www.runoob.com/mongodb/mongodb-tutorial.html  Official documentation: https://docs.mongodb.com/manual/  MongoDB-Python Driver: http://api.mongodb.com/python/current/tutorial.html?_ga=1.126571278.205344545.1483513991#tutorial", 
            "title": "Reference:"
        }, 
        {
            "location": "/preprocess/preprocess/", 
            "text": "Data Preprocessing\n\n\n\n\nFor machine learning tasks, the related types of data are as follows.\n\n\nDocuments\n\n\nImages\n\n\nVideos\n\n\nAudios\n\n\n\n\n\n\n3-V in Big Data:\n\n\nVolume: Size of datasets.\n\n\nVariety: Structrued (MySQL) \n Unstructured (MongoDB).\n\n\nVelocity: Speed at which data generates.\n\n\n\n\n\n\n\n\nRaw data can't be applied to data mining algorithms directly:\n\n\n\n\nNoise: Lead to low performance of the algorithm.\n\n\nIllegal datasets: Tedious execution time.\n\n\n\n\n\n\n\n\nLevel 1\n\n\n\n\nData cleaning (Noise/extreme points):\n\n\nEliminate extreme data points \n\n\nData visualization, clustering/regression/binning (must be sequential datasets) to delete those data points OR smoothen those data points\n\n\n\n\n\n\nFill in missing data fields \n\n\nOmit missing ones/setting average values/fill in most possible value (Decision Tree..., Clustering, K-means...)\n\n\n\n\n\n\n\n\n\n\nData integration:\n\n\nIntegrate resources from different databases\n\n\nProblems (Redundancy):\n\n\nSame info with different attribute names (eg: id, _id)\n\n\nSame info with different attribute values (eg: Bill, Gates)\n\n\nProblems resulting from the database updating\n\n\nNon-structured mixed with structured data (data dependency missing)\n\n\n\n\n\n\nSolutions:\n\n\nMatching based on meta-data (data type, range, specification) to judge whether two info represent the same object\n\n\nRedundancy (some data can be induced based on current data, eg: salary/year \n= salary/month): Kai square analysis (correlation analysis) to solve the data dependency problem.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nLevel 2\n\n\n\n\nData Transformation (Massive Datasets, optimize feature extracting):\n\n\nReduce the data fields to a given range (based on special functions, z-score...)\n\n\nExtract a higher concept layer (discrete) eg. young old ...\n\n\n\n\n\n\nData Reduction (Massive Datasets, optimize the data mining efficiency on the data level):\n\n\n[\nDimensional\n] Figure out an efficient data representation instead of applying massive raw datasets\n\n\nData encoding/compression (file type)\n\n\nAttribute Extracting (Select interesting fields)\n\n\n\n\n\n\n[\nNumerical\n]\n\n\nMathematical transformation to represent the same data with smaller scale:\n\n\nParametric Model (regression, linear model)\n\n\nNon-parametric Model (visualization, clustering, sampling)\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nBasic Workflow:\n\n\n\n\nFetch raw data\n\n\nData integration \n\n\nData cleaning \n\n\nStore clean data in HDFS (Hadoop Distribution File System)\n\n\nFetch level-1 preprocessed data\n\n\nData reduction\n\n\nData transformation\n\n\nRun the target algorithm\n\n\nStore results in HDFS\n\n\n\n\n\n\n\n\nUseful python libs:\n\n\n\n\nPandas\n\n\nScikit-Learn\n\n\nPySpark", 
            "title": "Overview"
        }, 
        {
            "location": "/preprocess/preprocess/#data-preprocessing", 
            "text": "For machine learning tasks, the related types of data are as follows.  Documents  Images  Videos  Audios    3-V in Big Data:  Volume: Size of datasets.  Variety: Structrued (MySQL)   Unstructured (MongoDB).  Velocity: Speed at which data generates.     Raw data can't be applied to data mining algorithms directly:   Noise: Lead to low performance of the algorithm.  Illegal datasets: Tedious execution time.     Level 1   Data cleaning (Noise/extreme points):  Eliminate extreme data points   Data visualization, clustering/regression/binning (must be sequential datasets) to delete those data points OR smoothen those data points    Fill in missing data fields   Omit missing ones/setting average values/fill in most possible value (Decision Tree..., Clustering, K-means...)      Data integration:  Integrate resources from different databases  Problems (Redundancy):  Same info with different attribute names (eg: id, _id)  Same info with different attribute values (eg: Bill, Gates)  Problems resulting from the database updating  Non-structured mixed with structured data (data dependency missing)    Solutions:  Matching based on meta-data (data type, range, specification) to judge whether two info represent the same object  Redundancy (some data can be induced based on current data, eg: salary/year  = salary/month): Kai square analysis (correlation analysis) to solve the data dependency problem.         Level 2   Data Transformation (Massive Datasets, optimize feature extracting):  Reduce the data fields to a given range (based on special functions, z-score...)  Extract a higher concept layer (discrete) eg. young old ...    Data Reduction (Massive Datasets, optimize the data mining efficiency on the data level):  [ Dimensional ] Figure out an efficient data representation instead of applying massive raw datasets  Data encoding/compression (file type)  Attribute Extracting (Select interesting fields)    [ Numerical ]  Mathematical transformation to represent the same data with smaller scale:  Parametric Model (regression, linear model)  Non-parametric Model (visualization, clustering, sampling)           Basic Workflow:   Fetch raw data  Data integration   Data cleaning   Store clean data in HDFS (Hadoop Distribution File System)  Fetch level-1 preprocessed data  Data reduction  Data transformation  Run the target algorithm  Store results in HDFS     Useful python libs:   Pandas  Scikit-Learn  PySpark", 
            "title": "Data Preprocessing"
        }, 
        {
            "location": "/preprocess/data_cleaning/", 
            "text": "Data Cleaning\n\n\n\n\nProblem I: Noise Points\n\n\nBehavior:\n\n\nClass noise: misclassification \n conflict class labels\n\n\nAttribute noise: attributes that influence the classification preformance\n\n\n\n\n\n\nSolution:\n\n\nNoise Filters\n\n\nGroup original datasets into T subsets\n\n\nFor each subset, run m filter/learning algorithms over other \nT-1\n subsets \n\n\nCompare the trained label with the actual label for each subset\n\n\nDecide the correctness of the initial labels by consensus vote scheme\n\n\nRemove the subset if far from idealism\n\n\n\n\n\n\nRobust Strategies (usually based on Machine Learning algorithms)\n\n\nFocus on the selection of the algorithms (eg. clustering...)\n\n\nNot much to deal with the data itself.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem II: Missed Data Fields \n\n\nBehavior:\n\n\nEntry A has attribute a, while Entry B doesn't have;\n\n\nEntry A originally has attribute a, while being eliminated by manual processing/error recording;\n\n\n\n\n\n\nSolution:\n\n\nOmitting\n\n\nIntro:\n\n\nDo nothing special\n\n\nJust assume they don't exist\n\n\n\n\n\n\nStrategies:\n\n\nListwise Deletion\n: Delete the whole problematic entry by ignoring other useful fields\n\n\nPairwise Deletion\n: Only delete the problematic field while keeping the useful fields\n\n\n\n\n\n\n\n\n\n\nSetting default values\n\n\nIntro:\n\n\nDeletion strategy may fail for small datasets\n\n\nGet imputed values, kind of guessing\n\n\n\n\n\n\nStrategies:\n\n\nSet the mean as default values\n: Retain the mean, but bad for field relationship\n\n\nLinear Regression\n: Amplify the current trends\n\n\n**Other Rob", 
            "title": "Data Cleaning"
        }, 
        {
            "location": "/preprocess/data_cleaning/#data-cleaning", 
            "text": "Problem I: Noise Points  Behavior:  Class noise: misclassification   conflict class labels  Attribute noise: attributes that influence the classification preformance    Solution:  Noise Filters  Group original datasets into T subsets  For each subset, run m filter/learning algorithms over other  T-1  subsets   Compare the trained label with the actual label for each subset  Decide the correctness of the initial labels by consensus vote scheme  Remove the subset if far from idealism    Robust Strategies (usually based on Machine Learning algorithms)  Focus on the selection of the algorithms (eg. clustering...)  Not much to deal with the data itself.        Problem II: Missed Data Fields   Behavior:  Entry A has attribute a, while Entry B doesn't have;  Entry A originally has attribute a, while being eliminated by manual processing/error recording;    Solution:  Omitting  Intro:  Do nothing special  Just assume they don't exist    Strategies:  Listwise Deletion : Delete the whole problematic entry by ignoring other useful fields  Pairwise Deletion : Only delete the problematic field while keeping the useful fields      Setting default values  Intro:  Deletion strategy may fail for small datasets  Get imputed values, kind of guessing    Strategies:  Set the mean as default values : Retain the mean, but bad for field relationship  Linear Regression : Amplify the current trends  **Other Rob", 
            "title": "Data Cleaning"
        }, 
        {
            "location": "/preprocess/data_integration/", 
            "text": "Data Integration\n\n\n\n\n\n\nProblem I: Attribute Redundancy\n\n\n\n\nBehavior:\n\n\nsalary/month =\n salary/year\n\n\n\n\n\n\nSolution:\n\n\nChi-Square Correlation Test\n\n\nIntro:\n\n\nHypothesis: \nAttr_A\n and \nAttr_B\n (both nominal attributes) are independent of each other\n\n\n\n\n\n\nStrategies:\n\n\nConstruct the contingency table: $A: a_1,a_2,...a_c; B: b_1,b_2,...b_r$\n\n\nApply the test formula:\n\n\n$\\chi^{2}=\\sum\\limits_{i=1}^{c}\\sum\\limits_{j=1}^{r}\\frac{(o_{ij}-e_{ij})^2}{e_{ij}}$ , $e_{ij}=\\frac{count(A=a_{i})\\cdot count(B=b_{j})}{m}$,\n\n\nwhere $o_{ij}$ is the observed occurrence, $e_{ij}$ is the expected occurrence, $m$ is the total number of instances in the datasets\n\n\nCompare with the Chi Square statistics:\n\n\nGiven significant level, and the degree of freedom $(c-1)(r-1)$, get the needed value in the Chi Square statistics reference table.\n\n\nReject the hypothesis if the computed result is above the needed one.\n\n\n\n\n\n\n\n\n\n\nCorrelation Coefficient and Covariance\n\n\nIntro:\n\n\nSimilar to Chi-Square Correlation Test\n\n\nApply a different statistical formula (numerical):\n\n\n$r_{A,B}=\\frac{\\sum_{i=1}^{m}(a_{i}-\\bar{A})(b_{i}-\\bar{B})}{m\\sigma_{A}\\sigma_{B}}=\\frac{\\sum_{i=1}^{m}(a_{i}b_{i}-m\\bar{A}\\bar{B})}{m\\sigma_{A}\\sigma_{B}}$,\n\n\n$Cov(A,B)=E((A-\\bar{A})(B-\\bar{B}))=\\frac{\\sum_{i=1}^{m}(a_{i}-\\bar{A})(b_{i}-\\bar{B})}{m}$.\n\n\n\n\n\n\nAnother validation condition:\n\n\nIndependent if covariance evaluated as 0.\n\n\n$Cov(A,B)=E(A,B)-\\bar{A}\\bar{B}=E(A)\\cdot E(B)-\\bar{A}\\bar{B}=0$\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nProblem II: Tuple Duplication and Inconsistency\n\n\n\n\nBehavior:\n\n\n\"id\" data field stored as \"_id\" in MySQL, while \"id\" in MongoDB\n\n\n\n\n\n\nSolution:\n\n\nMeta-data Comparison\n\n\nIntro:\n\n\nMeta-data: The data that describes our target data, eg: Type, range, etc. \n\n\n\n\n\n\nStrategies:\n\n\nCompare how the meta data of two fields are close to each other.\n\n\n\n\n\n\n\n\n\n\nEdit Distance\n\n\nIntro:\n\n\nQuantitatively evaluate how one string is close to the other.\n\n\n\n\n\n\nStrategies\n\n\nSet distance 1 for deletion, insertion, substitution.\n\n\nApply Dynamic Programming to get the target distance.\n\n\n$dist_{i,j}=min(dist_{i-1,j}+1,dist_{i,j-1}+1,dist_{i-1,j-1}+(match(S_{i},T_{j})?0:1))$", 
            "title": "Data Integration"
        }, 
        {
            "location": "/preprocess/data_integration/#data-integration", 
            "text": "Problem I: Attribute Redundancy   Behavior:  salary/month =  salary/year    Solution:  Chi-Square Correlation Test  Intro:  Hypothesis:  Attr_A  and  Attr_B  (both nominal attributes) are independent of each other    Strategies:  Construct the contingency table: $A: a_1,a_2,...a_c; B: b_1,b_2,...b_r$  Apply the test formula:  $\\chi^{2}=\\sum\\limits_{i=1}^{c}\\sum\\limits_{j=1}^{r}\\frac{(o_{ij}-e_{ij})^2}{e_{ij}}$ , $e_{ij}=\\frac{count(A=a_{i})\\cdot count(B=b_{j})}{m}$,  where $o_{ij}$ is the observed occurrence, $e_{ij}$ is the expected occurrence, $m$ is the total number of instances in the datasets  Compare with the Chi Square statistics:  Given significant level, and the degree of freedom $(c-1)(r-1)$, get the needed value in the Chi Square statistics reference table.  Reject the hypothesis if the computed result is above the needed one.      Correlation Coefficient and Covariance  Intro:  Similar to Chi-Square Correlation Test  Apply a different statistical formula (numerical):  $r_{A,B}=\\frac{\\sum_{i=1}^{m}(a_{i}-\\bar{A})(b_{i}-\\bar{B})}{m\\sigma_{A}\\sigma_{B}}=\\frac{\\sum_{i=1}^{m}(a_{i}b_{i}-m\\bar{A}\\bar{B})}{m\\sigma_{A}\\sigma_{B}}$,  $Cov(A,B)=E((A-\\bar{A})(B-\\bar{B}))=\\frac{\\sum_{i=1}^{m}(a_{i}-\\bar{A})(b_{i}-\\bar{B})}{m}$.    Another validation condition:  Independent if covariance evaluated as 0.  $Cov(A,B)=E(A,B)-\\bar{A}\\bar{B}=E(A)\\cdot E(B)-\\bar{A}\\bar{B}=0$             Problem II: Tuple Duplication and Inconsistency   Behavior:  \"id\" data field stored as \"_id\" in MySQL, while \"id\" in MongoDB    Solution:  Meta-data Comparison  Intro:  Meta-data: The data that describes our target data, eg: Type, range, etc.     Strategies:  Compare how the meta data of two fields are close to each other.      Edit Distance  Intro:  Quantitatively evaluate how one string is close to the other.    Strategies  Set distance 1 for deletion, insertion, substitution.  Apply Dynamic Programming to get the target distance.  $dist_{i,j}=min(dist_{i-1,j}+1,dist_{i,j-1}+1,dist_{i-1,j-1}+(match(S_{i},T_{j})?0:1))$", 
            "title": "Data Integration"
        }, 
        {
            "location": "/preprocess/data_reduction_overview/", 
            "text": "Data Reduction\n\n\n\n\n\n\nData redcution can be devided into 3 categories\n\n\n\n\ndimension reduction\n\n\nsample numerosity reduction\n\n\ncardinality reduction\n\n\n\n\n\n\n\n\nDimension Reduction (DR):\n\n\n\n\n\n\nwhy we need it? the curse of dimension\n number of training samples should grows linearly or even exponentially with the dimensions. For exaample, when dealing with non-parametric learners, such as decision tree.\n\n\n\n\n\n\nPCA: normalize the input data, get the principal components by calculating the eigenvalues-eigenvectors of the covariance matrix of the original data, sort by the eigenvalues, reduce weaker components\n\n\n\n\n\n\nFactor Analysis: Discover hiddeen factos in the current variables. Assume that there is a set of latent varaibels that generate the original data. Major method is using PCA. (, the eigenvalues of PCA are inflated component loadings, i.e., contaminated with error variance, from wikipedia)\nTherefore in my opinion, this maybe that factor analysis introduce an error item and it will estimate it recursively until it converge(it may not!) before hand.\n\n\n\n\n\n\nMutidimensional scaling: it reduces the data into a space that the distance between each other is minimized. Too much mathematics. \n\n\n\n\n\n\nLocally linear embedding: Assume data lies in a manifold with dimension d \n D like a line in a plain. Each point can be revcovered by its neightbor. It preserve the invariance to rotation and scaling. Then we can use the weight to get the d-dimensional coordinate by fixing the weight and finding the d-dimensional coordinate to minimize teh sqarue distances of all points.\n\n\n\n\n\n\n\n\n\n\nData Sampling \n\n\n\n\n\n\nwhy?\n\n\n\n\nreduce the number of instances submitted to the data mining algorithm. Predictive learning often can have 10%-20% of data to learn without the dererioration of performance.\n\n\nbalancing the data, like oversampling the rare case and undersampling the common case\n\n\npartition into training , validation and testing sets.\n\n\n\n\n\n\n\n\nmethod\n\n\n\n\nsimple random sample without replacement\n\n\nsimple random sample with replacement\n\n\nbalanced sample\n\n\nclusters sample, like samples in geographically separated areas.\n\n\nstratified ssample\n\n\n\n\n\n\n\n\ndata condensation: selection of small representatives\n\n\n\n\n\n\ndata squashing: use a compressed set of data such that hte staistical properties are preserved\n\n\n\n\n\n\ndata clustering: use the cluster instead of the data itself\n\n\n\n\n\n\n\n\n\n\nbining and reduction of cardinality\n\n\n\n\nbining is discretize the continuous data into discrete ones which cover different ranges. combine different categories into one indicator variable, reducing the possibility that original category has trivially almost all 0 or 1.\n\n\n\n\n\n\n\n\n\n\nFeature Selection\n\n\n\n\n\n\nFeature Relevance\n\n\nFeature relevance is an abstract concept in terms of an ideal Bayes classifier\n\n\n\n\n\n\nstrongly relevant if remove the feature X will result in the deterioration of the classification results\n\n\n\n\n\n\nweakly relevant if there exisits a set S that performance is better when using S U {X} than S.\n\n\n\n\n\n\nirrelevant if neither weakly or strong relevant\n\n\n\n\n\n\nNote\n: The difference between stong and weakly is that one is for  all set and one only requires existence.\n\n\n\n\n\n\nFeature Selection Method\n\n\n\n\n\n\nindivisual searching vs subset searching\n\n\n\n\n\n\nfilters, wrappers and embedded methods\n\n\n\n\n\n\nFilter method\n\n\n\n\nchi-Sqaured: univariate, the higher teh chi-squared, the more relkevant the feature with tespect to the class.\n\n\ninformation gain: entorpy orginal - entropy psterior\n\n\nCorrelea=ation-Based Feature Selection.: multivariate, the more the fetaure related with the class and the less with the orther feature, the more it is selected.\n\n\nRelieF: improved version of Relief algorithm. The attributes that separate the same class is insisgificant and the attributes that separate different calsses is desirable.\n\nRelieFCode\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInstance Selection\n\n\n\n\n\n\nOverview\n\n\n\n\n\n\ntwo main method: select training set, select prototype.\n\n\n\n\n\n\ninstance selection is to select the data subset such as the whole set is used. In other words, it is like reduce redundancy.\n\n\n\n\n\n\nIt is like select a set from the training set and test it over the test set(the test set is the same for comparison purpose)\n\n\n\n\n\n\nPS methods: prototype selection. This method uses an instance base classifier to divide the training set with measure like similarity and distance measure. \n\n\n\n\n\n\nTSS method: training set selection. It is more like a way to inmprove the interpretability and precision of a predictive model. Most common applications are ANNs, SVMs and decision trees.\n\n\n\n\n\n\n\n\n\n\nPrototype method\n\n\n\n\n\n\nDirection of search\n\n\n\n\nincremental\n\n\ndecremental\n\n\nbatch: based on decremental, remove instances in batch\n\n\nmixed: start with a preselected subset, and hthen add or remove instances \n\n\n\n\n\n\n\n\nType of selection\n\n\n\n\ncondensation: retain the points in the decision boundary, and remove the internal one: high reduction scale but low accuracy on test sets (due to overfitting)\n\n\nedition: remove noisy border point: high accruracy but low reduction\n\n\nHybrid\n\n\n\n\n\n\n\n\nEvaluation of search\n\n\n\n\nfilter\n\n\nwrapper\n\n\n\n\n\n\n\n\nCriteria \n\n\n\n\nstorage reduction\n\n\ngeneralization accuracy\n\n\nnoise tolenrance\n\n\ntime complexity\n\n\n\n\n\n\n\n\nMethod\n\n\n\n\n\n\ncondensation algorithms\n\n\n\n\n\n\nincremental CNN\n\n\ncondensed nearest neighborsrandomly select one instance belonging to each output class from TR and put them in a set S. Classify other instances in the TR using the instances in S, using the nearest neighbors. When misclassified, it is added to S, thus ensuring it is not misclassifed.   \n\n\n\n\n\n\ndecremental \n\n\n\n\n\n\nRNN: reduced nearest neighbors. S = TR, remove an instance that does not impact other instances' classification. \n\n\n\n\n\n\nShrink: Similar to RNN, but consider only the removed one is correctly classified or not.\n\n\n\n\n\n\nMinimal Consistent Set (This method is like Go, the instance with more own class neighbor wins)\n\n\nconsistency is the key word. And before that we need to know NUN dist = Nearest unlike neighbots dist. Instance is consistent when it has NUN dist greater than the dist between it and the nearest unlike neighbor( by definition )\nThe iteration starts with the entire set. Then remove inconsistent instances.\nEach instance has a vote, which is given by the own-class neighbors who are within the NUN distance range. Then we would like to starts with the candidate with the largest votes and then eliminate the voters that vote it (because it is a selected representitive.) Repeat this procedure until all instanse in the set has been considered.\nRepeat since NUN may change during the above procedures. All procedures can be repeated until convergence.     \n\n\n\n\n\n\n\n\n\n\nEdition algorithm\n\n\n\n\nEdited  NN: instance is deleted when it does not agree with the nearest k neighbors\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nDiscretization\n\n\n\n\n\n\nMotivation\n\n\n\n\nsome data mining algorithms require discrete values.\n\n\nit can be more efficient when training\n** Note: it may lose information of the data, thus minimizatinon of information loss is the main goal of a discretizer.\n\n\n\n\n\n\n\n\nMore\n\n\n\n\nobtaining an optimal discrezation is NP complete.\n\n\narity: the number of patitions\n\n\nprocedures: sort attribute -\n obtain cut points -\n perform evaluation -\n split/merge attribute -\n stop criterion\n\n\n\n\n\n\n\n\nCommon Properties\n\n\n\n\nstatic vs dynamic: dynamic discretizer is in relation to the learner. Almost all disretizer is static.\n\n\nunivariate vs multivariate: multivatiate: 2D discretization - considering two attributes at the same time to find the best cut points.\n\n\nsupervised vs unsupervised: unsupervised does not consider the class labels. In supervised discretizers, the heuristic measures such as entropy and interdenpendecy are used to dermine the best cut points.\n\n\nspliting vs merging: top down and bottom up\n\n\nglobal vs local: either all the available data or use only partial information. Few discretizers are local.\n\n\ndirect vs incremental: divide into k intervals simultaneously or perfect the division step by step.\n\n\nevaluation measrues:\n\n\ninformation: entropy\n\n\nstatistical: dependency\n\n\nrough sets: lower and uppper approximation, class separativity.\n\n\nwrapper: error rate provided by a classifier\n\n\nbinning: absense of evaluation measure. EqualWidth and EqualFrequency.\n\n\n\n\n\n\n\n\n\n\n\n\nCriterion to compare discretization methods\n\n\n\n\nnumber of intervals, the smaller the better\n\n\ninconsistency. unavoidable measure: two instances with the same input attribute but different class labels.\n\n\npredictive classification rate\n\n\ntime requirement\n\n\n\n\n\n\n\n\nSpliting Methods\n\n\n\n\nEqual width and equal frequency. equal frequency is in terms of continuous value, then the length of the interval can be found by dividing the length of the whole interval with desired arity. It is also equal width. \n\n\nMDLP.\n\n\nuse entropy to measure cut points\n\n\nminimum disccription length principle to decide the acceptation o rejection for each cut pouint as the stopping criterion. The length of bits needed to distinguish an object. It stops when the information gain exceeds a value.\n\n\n\n\n\n\nDistance \n\n\nMantaras distance\n\n\nit chooses the cut points that minimize the distance.\n\n\n\n\n\n\nPKID: proportional discretization (to the size of data set). Desired interval frequencies and desired interval number are equal.\n\n\nFFD: fixed frequency discretization. Fixed frequency and then divide. Compared to equal frequncy, which fixed number of interval and then divide according to equal frequency.\n\n\n\n\n\n\n\n\nMerging Method", 
            "title": "Data Reduction"
        }, 
        {
            "location": "/preprocess/data_reduction_overview/#data-reduction", 
            "text": "Data redcution can be devided into 3 categories   dimension reduction  sample numerosity reduction  cardinality reduction     Dimension Reduction (DR):    why we need it? the curse of dimension\n number of training samples should grows linearly or even exponentially with the dimensions. For exaample, when dealing with non-parametric learners, such as decision tree.    PCA: normalize the input data, get the principal components by calculating the eigenvalues-eigenvectors of the covariance matrix of the original data, sort by the eigenvalues, reduce weaker components    Factor Analysis: Discover hiddeen factos in the current variables. Assume that there is a set of latent varaibels that generate the original data. Major method is using PCA. (, the eigenvalues of PCA are inflated component loadings, i.e., contaminated with error variance, from wikipedia)\nTherefore in my opinion, this maybe that factor analysis introduce an error item and it will estimate it recursively until it converge(it may not!) before hand.    Mutidimensional scaling: it reduces the data into a space that the distance between each other is minimized. Too much mathematics.     Locally linear embedding: Assume data lies in a manifold with dimension d   D like a line in a plain. Each point can be revcovered by its neightbor. It preserve the invariance to rotation and scaling. Then we can use the weight to get the d-dimensional coordinate by fixing the weight and finding the d-dimensional coordinate to minimize teh sqarue distances of all points.      Data Sampling     why?   reduce the number of instances submitted to the data mining algorithm. Predictive learning often can have 10%-20% of data to learn without the dererioration of performance.  balancing the data, like oversampling the rare case and undersampling the common case  partition into training , validation and testing sets.     method   simple random sample without replacement  simple random sample with replacement  balanced sample  clusters sample, like samples in geographically separated areas.  stratified ssample     data condensation: selection of small representatives    data squashing: use a compressed set of data such that hte staistical properties are preserved    data clustering: use the cluster instead of the data itself      bining and reduction of cardinality   bining is discretize the continuous data into discrete ones which cover different ranges. combine different categories into one indicator variable, reducing the possibility that original category has trivially almost all 0 or 1.", 
            "title": "Data Reduction"
        }, 
        {
            "location": "/preprocess/data_reduction_overview/#feature-selection", 
            "text": "Feature Relevance  Feature relevance is an abstract concept in terms of an ideal Bayes classifier    strongly relevant if remove the feature X will result in the deterioration of the classification results    weakly relevant if there exisits a set S that performance is better when using S U {X} than S.    irrelevant if neither weakly or strong relevant    Note : The difference between stong and weakly is that one is for  all set and one only requires existence.    Feature Selection Method    indivisual searching vs subset searching    filters, wrappers and embedded methods    Filter method   chi-Sqaured: univariate, the higher teh chi-squared, the more relkevant the feature with tespect to the class.  information gain: entorpy orginal - entropy psterior  Correlea=ation-Based Feature Selection.: multivariate, the more the fetaure related with the class and the less with the orther feature, the more it is selected.  RelieF: improved version of Relief algorithm. The attributes that separate the same class is insisgificant and the attributes that separate different calsses is desirable. RelieFCode", 
            "title": "Feature Selection"
        }, 
        {
            "location": "/preprocess/data_reduction_overview/#instance-selection", 
            "text": "Overview    two main method: select training set, select prototype.    instance selection is to select the data subset such as the whole set is used. In other words, it is like reduce redundancy.    It is like select a set from the training set and test it over the test set(the test set is the same for comparison purpose)    PS methods: prototype selection. This method uses an instance base classifier to divide the training set with measure like similarity and distance measure.     TSS method: training set selection. It is more like a way to inmprove the interpretability and precision of a predictive model. Most common applications are ANNs, SVMs and decision trees.      Prototype method    Direction of search   incremental  decremental  batch: based on decremental, remove instances in batch  mixed: start with a preselected subset, and hthen add or remove instances      Type of selection   condensation: retain the points in the decision boundary, and remove the internal one: high reduction scale but low accuracy on test sets (due to overfitting)  edition: remove noisy border point: high accruracy but low reduction  Hybrid     Evaluation of search   filter  wrapper     Criteria    storage reduction  generalization accuracy  noise tolenrance  time complexity     Method    condensation algorithms    incremental CNN  condensed nearest neighborsrandomly select one instance belonging to each output class from TR and put them in a set S. Classify other instances in the TR using the instances in S, using the nearest neighbors. When misclassified, it is added to S, thus ensuring it is not misclassifed.       decremental     RNN: reduced nearest neighbors. S = TR, remove an instance that does not impact other instances' classification.     Shrink: Similar to RNN, but consider only the removed one is correctly classified or not.    Minimal Consistent Set (This method is like Go, the instance with more own class neighbor wins)  consistency is the key word. And before that we need to know NUN dist = Nearest unlike neighbots dist. Instance is consistent when it has NUN dist greater than the dist between it and the nearest unlike neighbor( by definition )\nThe iteration starts with the entire set. Then remove inconsistent instances.\nEach instance has a vote, which is given by the own-class neighbors who are within the NUN distance range. Then we would like to starts with the candidate with the largest votes and then eliminate the voters that vote it (because it is a selected representitive.) Repeat this procedure until all instanse in the set has been considered.\nRepeat since NUN may change during the above procedures. All procedures can be repeated until convergence.           Edition algorithm   Edited  NN: instance is deleted when it does not agree with the nearest k neighbors", 
            "title": "Instance Selection"
        }, 
        {
            "location": "/preprocess/data_reduction_overview/#discretization", 
            "text": "Motivation   some data mining algorithms require discrete values.  it can be more efficient when training\n** Note: it may lose information of the data, thus minimizatinon of information loss is the main goal of a discretizer.     More   obtaining an optimal discrezation is NP complete.  arity: the number of patitions  procedures: sort attribute -  obtain cut points -  perform evaluation -  split/merge attribute -  stop criterion     Common Properties   static vs dynamic: dynamic discretizer is in relation to the learner. Almost all disretizer is static.  univariate vs multivariate: multivatiate: 2D discretization - considering two attributes at the same time to find the best cut points.  supervised vs unsupervised: unsupervised does not consider the class labels. In supervised discretizers, the heuristic measures such as entropy and interdenpendecy are used to dermine the best cut points.  spliting vs merging: top down and bottom up  global vs local: either all the available data or use only partial information. Few discretizers are local.  direct vs incremental: divide into k intervals simultaneously or perfect the division step by step.  evaluation measrues:  information: entropy  statistical: dependency  rough sets: lower and uppper approximation, class separativity.  wrapper: error rate provided by a classifier  binning: absense of evaluation measure. EqualWidth and EqualFrequency.       Criterion to compare discretization methods   number of intervals, the smaller the better  inconsistency. unavoidable measure: two instances with the same input attribute but different class labels.  predictive classification rate  time requirement     Spliting Methods   Equal width and equal frequency. equal frequency is in terms of continuous value, then the length of the interval can be found by dividing the length of the whole interval with desired arity. It is also equal width.   MDLP.  use entropy to measure cut points  minimum disccription length principle to decide the acceptation o rejection for each cut pouint as the stopping criterion. The length of bits needed to distinguish an object. It stops when the information gain exceeds a value.    Distance   Mantaras distance  it chooses the cut points that minimize the distance.    PKID: proportional discretization (to the size of data set). Desired interval frequencies and desired interval number are equal.  FFD: fixed frequency discretization. Fixed frequency and then divide. Compared to equal frequncy, which fixed number of interval and then divide according to equal frequency.     Merging Method", 
            "title": "Discretization"
        }, 
        {
            "location": "/algorithm/overview/", 
            "text": "Supervised Learning\n\n\nSupervised learning is the machine learning task of inferring a function from labeled training data. The training data consist of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal).\n\n\n\n\nUnsupervised Learning\n\n\nUnsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.\n\n\n\n\nSemi-supervised Learning\n\n\nSemi-supervised learning is a class of supervised learning tasks and techniques that also make use of unlabeled data for training \u2013 typically a small amount of labeled data with a large amount of unlabeled data.\n\n\nReinforcement Learning\n\n\nIn reinforcement learning, the algorithm gets \nto choose an action in response to each data point. \nThe learning algorithm also receives a reward \nsignal a short time later, indicating how good the \ndecision was. Based on this, the algorithm modifies \nits strategy in order to achieve the highest reward. \nReinforcement learning is common in robotics, where the set of sensor readings at one point in time is a data point, and the algorithm must choose the robot's next action. It is also a natural fit for Internet of Things applications.\n\n\nDeep Learning\n\n\nDeep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in data by using multiple processing layers, with complex structures or otherwise, composed of multiple non-linear transformations.\n\n\nAlgorithm Map", 
            "title": "Overview"
        }, 
        {
            "location": "/algorithm/overview/#supervised-learning", 
            "text": "Supervised learning is the machine learning task of inferring a function from labeled training data. The training data consist of a set of training examples. In supervised learning, each example is a pair consisting of an input object (typically a vector) and a desired output value (also called the supervisory signal).", 
            "title": "Supervised Learning"
        }, 
        {
            "location": "/algorithm/overview/#unsupervised-learning", 
            "text": "Unsupervised learning is a type of machine learning algorithm used to draw inferences from datasets consisting of input data without labeled responses. The most common unsupervised learning method is cluster analysis, which is used for exploratory data analysis to find hidden patterns or grouping in data.", 
            "title": "Unsupervised Learning"
        }, 
        {
            "location": "/algorithm/overview/#semi-supervised-learning", 
            "text": "Semi-supervised learning is a class of supervised learning tasks and techniques that also make use of unlabeled data for training \u2013 typically a small amount of labeled data with a large amount of unlabeled data.", 
            "title": "Semi-supervised Learning"
        }, 
        {
            "location": "/algorithm/overview/#reinforcement-learning", 
            "text": "In reinforcement learning, the algorithm gets \nto choose an action in response to each data point. \nThe learning algorithm also receives a reward \nsignal a short time later, indicating how good the \ndecision was. Based on this, the algorithm modifies \nits strategy in order to achieve the highest reward. \nReinforcement learning is common in robotics, where the set of sensor readings at one point in time is a data point, and the algorithm must choose the robot's next action. It is also a natural fit for Internet of Things applications.", 
            "title": "Reinforcement Learning"
        }, 
        {
            "location": "/algorithm/overview/#deep-learning", 
            "text": "Deep learning (also known as deep structured learning, hierarchical learning or deep machine learning) is a branch of machine learning based on a set of algorithms that attempt to model high-level abstractions in data by using multiple processing layers, with complex structures or otherwise, composed of multiple non-linear transformations.", 
            "title": "Deep Learning"
        }, 
        {
            "location": "/algorithm/overview/#algorithm-map", 
            "text": "", 
            "title": "Algorithm Map"
        }, 
        {
            "location": "/algorithm/nn/", 
            "text": "Neural Network\n\n\nAn artificial neutral network (ANN) is a system that is based on the biological neural network.\n\n\nAn ANN is comprised of a network of artificial neurons (also known as \"nodes\"). These nodes are connected to each other, and the strength of their connections to one another is assigned a value based on their strength: inhibition or excitation. If the value of the connection is high, then it indicates that there is a strong connection.\nWithin each node's design, a transfer function is built in.\n\n\nThere are three types of neurons in an ANN, input nodes, hidden nodes, and output nodes.\n\n\n\n\nThe input nodes take in information, in the form which can be numerically expressed. The information is presented as activation values, where each node is given a number.\n\n\nThis information is then passed throughout the network. Based on the connection strengths (weights), inhibition or excitation, and transfer functions, the activation value is passed from node to node. Each of the nodes sums the activation values it receives; it then modifies the value based on its transfer function.\n\n\nThe activation flows through the network, through hidden layers, until it reaches the output nodes. The output nodes then reflect the input in a meaningful way to the outside world.\n\n\nThe difference between predicted value and actual value (error) will be propagated backward by apportioning them to each node's weights according to the amount of this error the node is responsible for (e.g., gradient descent algorithm).\n\n\nThere are different types of neural networks, but they are generally classified into feed-forward and feed-back networks.\n\n\nA feed-forward network\n\n\n\n\n\n\nA non-recurrent network which contains inputs, outputs, and hidden layers; the signals can only travel in one direction.\n\n\n\n\n\n\nInput data is passed onto a layer of processing elements where it performs calculations. Each processing element makes its computation based upon a weighted sum of its inputs. The new calculated values then become the new input values that feed the next layer. This process continues until it has gone through all the layers and determines the output.\n\n\n\n\n\n\nA threshold transfer function is sometimes used to quantify the output of a neuron in the output layer.\n\n\n\n\n\n\nFeed-forward networks include Perceptron (linear and non-linear) and Radial Basis Function networks.\n\n\n\n\n\n\nFeed-forward networks are often used in data mining.\n\n\n\n\n\n\nCommon Examples are Perceptrons, Back Propagation Network, and Radial Basis Function Network.\n\n\n\n\n\n\nA feed-back network\n\n\n\n\n\n\nthey can have signals traveling in both directions using loops.\n\n\n\n\n\n\nAll possible connections between neurons are allowed.\n\n\n\n\n\n\nSince loops are present in this type of network, it becomes a non-linear dynamic system which changes continuously until it reaches a state of equilibrium.\n\n\n\n\n\n\nFeed-back networks are often used in associative memories and optimization problems where the network looks for the best arrangement of interconnected factors.\n\n\n\n\n\n\nCommon Examples are Boltzmann machine and Hopfield network.", 
            "title": "Neural Network"
        }, 
        {
            "location": "/algorithm/nn/#neural-network", 
            "text": "An artificial neutral network (ANN) is a system that is based on the biological neural network.  An ANN is comprised of a network of artificial neurons (also known as \"nodes\"). These nodes are connected to each other, and the strength of their connections to one another is assigned a value based on their strength: inhibition or excitation. If the value of the connection is high, then it indicates that there is a strong connection.\nWithin each node's design, a transfer function is built in.  There are three types of neurons in an ANN, input nodes, hidden nodes, and output nodes.   The input nodes take in information, in the form which can be numerically expressed. The information is presented as activation values, where each node is given a number.  This information is then passed throughout the network. Based on the connection strengths (weights), inhibition or excitation, and transfer functions, the activation value is passed from node to node. Each of the nodes sums the activation values it receives; it then modifies the value based on its transfer function.  The activation flows through the network, through hidden layers, until it reaches the output nodes. The output nodes then reflect the input in a meaningful way to the outside world.  The difference between predicted value and actual value (error) will be propagated backward by apportioning them to each node's weights according to the amount of this error the node is responsible for (e.g., gradient descent algorithm).  There are different types of neural networks, but they are generally classified into feed-forward and feed-back networks.", 
            "title": "Neural Network"
        }, 
        {
            "location": "/algorithm/nn/#a-feed-forward-network", 
            "text": "A non-recurrent network which contains inputs, outputs, and hidden layers; the signals can only travel in one direction.    Input data is passed onto a layer of processing elements where it performs calculations. Each processing element makes its computation based upon a weighted sum of its inputs. The new calculated values then become the new input values that feed the next layer. This process continues until it has gone through all the layers and determines the output.    A threshold transfer function is sometimes used to quantify the output of a neuron in the output layer.    Feed-forward networks include Perceptron (linear and non-linear) and Radial Basis Function networks.    Feed-forward networks are often used in data mining.    Common Examples are Perceptrons, Back Propagation Network, and Radial Basis Function Network.", 
            "title": "A feed-forward network"
        }, 
        {
            "location": "/algorithm/nn/#a-feed-back-network", 
            "text": "they can have signals traveling in both directions using loops.    All possible connections between neurons are allowed.    Since loops are present in this type of network, it becomes a non-linear dynamic system which changes continuously until it reaches a state of equilibrium.    Feed-back networks are often used in associative memories and optimization problems where the network looks for the best arrangement of interconnected factors.    Common Examples are Boltzmann machine and Hopfield network.", 
            "title": "A feed-back network"
        }, 
        {
            "location": "/algorithm/svm/", 
            "text": "Support Vector Machine\n\n\nIf the training data are linearly separable, we can select two hyperplanes in a way such that it separates the data and the distance between the data are maximized. The regeion bound by them is called \"the margin\".\n\n\n\n\nThe plane can be describe as \n\n\n\\textbf{w}^T \\textbf{x} + b = 0\n\n\n\n\n\nAs \nw\n and b could by scaled by any rate, we can normalize the two hyperplanes as \n\n\n\\textbf{w}^T \\textbf{x} + b = 1 \\\\\n\\textbf{w}^T \\textbf{x} + b = -1\n\n\n\n\n\nAnd we can get the constraint\n\n\ny^{(i)}(\\textbf{w}^T \\textbf{x}^{(i)} + b) \\geq 1\n\n\nfor each i = 1,2,...m.\n\n\nGeometrically, the distance between these two hyperplanes is \n \\frac{2}{||\\textbf{w}||^2}\n, so we need to minimize \n\\frac{1}{2}||\\textbf{w}||^2 \n.\n\n\nThen the question turns into: \n\n\nmin \\frac{1}{2}||\\textbf{w}||^2 \\\\\ns.t. y^{(i)}(\\textbf{w}^T \\textbf{x}^{(i)} + b) \\geq 1, i = 1,2,...,m\n\n\n\n\n\nKernel\n\n\nIn real case, we need to separate data that are not linearly separable. The basic idea is to map the data into higher dimensional space . The classifier is a hyperplane in the high-dimensional space.\n\n\n\n\nGiven training data, \n(\\textbf{x}^{(1)}, y^{(1)}), (\\textbf{x}^{(2)}, y^{(2)}) ... (\\textbf{x}^{(m)}, y^{(m)})\n, for each \n\\textbf{x}^{(i)}\n, we calculate the m-dimensional \n\\textbf{f}^{(i)}\n:\n\n\n\\textbf{f}^{(i)}_1 = K(\\textbf{x}^{(i)}, \\textbf{x}^{(1)}),\\textbf{f}^{(i)}_2 = K(\\textbf{x}^{(i)}, \\textbf{x}^{(2)}),..., \\textbf{f}^{(i)}_m = K(\\textbf{x}^{(i)}, \\textbf{x}^{(m)})\n\n\n\n\n\nThe original question turns into:\n\n\nmin \\frac{1}{2}||\\textbf{a}||^2 \\\\\ns.t. y^{(i)}(\\textbf{a}^T \\textbf{f}^{(i)} + b) \\geq 1, i = 1,2,...,m\n\n\n\n\n\nCommon Kernels\n\n\n\n\n\n\nLinear: \nK(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}\n\n\n\n\n\n\n\n\nPolynomial: \nK(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=(\\gamma\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}+r)^d, \\gamma > 0 \n\n\n\n\n\n\n\n\nRadial Basis FUction (RBF): \nK(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=exp(-\\gamma||\\textbf{x}^{(i)}-\\textbf{x}^{(j)}||^2), \\gamma > 0 \n\n\n\n\n\n\n\n\nSigmoid: \nK(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=tanh(\\gamma\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}+r)", 
            "title": "Support Vector Machine"
        }, 
        {
            "location": "/algorithm/svm/#support-vector-machine", 
            "text": "If the training data are linearly separable, we can select two hyperplanes in a way such that it separates the data and the distance between the data are maximized. The regeion bound by them is called \"the margin\".   The plane can be describe as  \n\\textbf{w}^T \\textbf{x} + b = 0   As  w  and b could by scaled by any rate, we can normalize the two hyperplanes as  \n\\textbf{w}^T \\textbf{x} + b = 1 \\\\\n\\textbf{w}^T \\textbf{x} + b = -1   And we can get the constraint \ny^{(i)}(\\textbf{w}^T \\textbf{x}^{(i)} + b) \\geq 1 \nfor each i = 1,2,...m.  Geometrically, the distance between these two hyperplanes is   \\frac{2}{||\\textbf{w}||^2} , so we need to minimize  \\frac{1}{2}||\\textbf{w}||^2  .  Then the question turns into:  \nmin \\frac{1}{2}||\\textbf{w}||^2 \\\\\ns.t. y^{(i)}(\\textbf{w}^T \\textbf{x}^{(i)} + b) \\geq 1, i = 1,2,...,m", 
            "title": "Support Vector Machine"
        }, 
        {
            "location": "/algorithm/svm/#kernel", 
            "text": "In real case, we need to separate data that are not linearly separable. The basic idea is to map the data into higher dimensional space . The classifier is a hyperplane in the high-dimensional space.   Given training data,  (\\textbf{x}^{(1)}, y^{(1)}), (\\textbf{x}^{(2)}, y^{(2)}) ... (\\textbf{x}^{(m)}, y^{(m)}) , for each  \\textbf{x}^{(i)} , we calculate the m-dimensional  \\textbf{f}^{(i)} : \n\\textbf{f}^{(i)}_1 = K(\\textbf{x}^{(i)}, \\textbf{x}^{(1)}),\\textbf{f}^{(i)}_2 = K(\\textbf{x}^{(i)}, \\textbf{x}^{(2)}),..., \\textbf{f}^{(i)}_m = K(\\textbf{x}^{(i)}, \\textbf{x}^{(m)})   The original question turns into: \nmin \\frac{1}{2}||\\textbf{a}||^2 \\\\\ns.t. y^{(i)}(\\textbf{a}^T \\textbf{f}^{(i)} + b) \\geq 1, i = 1,2,...,m   Common Kernels    Linear:  K(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}     Polynomial:  K(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=(\\gamma\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}+r)^d, \\gamma > 0      Radial Basis FUction (RBF):  K(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=exp(-\\gamma||\\textbf{x}^{(i)}-\\textbf{x}^{(j)}||^2), \\gamma > 0      Sigmoid:  K(\\textbf{x}^{(i)}, \\textbf{x}^{(j)})=tanh(\\gamma\\textbf{x}^{(i)^{\\textbf{T}}}\\textbf{x}^{(j)}+r)", 
            "title": "Kernel"
        }, 
        {
            "location": "/algorithm/tree/", 
            "text": "Decision Tree\n\n\nDecision tree builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes. \n\n\nDecision tree learning is the construction of a decision tree from class-labeled training tuples. A decision tree is a flow-chart-like structure, where each internal (non-leaf) node denotes a test on an attribute, each branch represents the outcome of a test, and each leaf (or terminal) node holds a class label. The topmost node in a tree is the root node.\n\n\nThere are many specific decision-tree algorithms. Notable ones include:\n\n\n\n\nID3 (Iterative Dichotomiser 3)\n\n\nC4.5 (successor of ID3)\n\n\nCART (Classification And Regression Tree)\n\n\nCHAID (CHi-squared Automatic Interaction Detector). Performs multi-level splits when computing classification trees.\n\n\nMARS: extends decision trees to handle numerical data better.\n\n\nConditional Inference Trees. Statistics-based approach that uses non-parametric tests as splitting criteria, corrected for multiple testing to avoid overfitting. This approach results in unbiased predictor selection and does not require pruning.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nRandom Forest", 
            "title": "Decision Tree & Random Forest"
        }, 
        {
            "location": "/algorithm/tree/#decision-tree", 
            "text": "Decision tree builds classification or regression models in the form of a tree structure. It breaks down a dataset into smaller and smaller subsets while at the same time an associated decision tree is incrementally developed. The final result is a tree with decision nodes and leaf nodes.   Decision tree learning is the construction of a decision tree from class-labeled training tuples. A decision tree is a flow-chart-like structure, where each internal (non-leaf) node denotes a test on an attribute, each branch represents the outcome of a test, and each leaf (or terminal) node holds a class label. The topmost node in a tree is the root node.  There are many specific decision-tree algorithms. Notable ones include:   ID3 (Iterative Dichotomiser 3)  C4.5 (successor of ID3)  CART (Classification And Regression Tree)  CHAID (CHi-squared Automatic Interaction Detector). Performs multi-level splits when computing classification trees.  MARS: extends decision trees to handle numerical data better.  Conditional Inference Trees. Statistics-based approach that uses non-parametric tests as splitting criteria, corrected for multiple testing to avoid overfitting. This approach results in unbiased predictor selection and does not require pruning.", 
            "title": "Decision Tree"
        }, 
        {
            "location": "/algorithm/tree/#random-forest", 
            "text": "", 
            "title": "Random Forest"
        }, 
        {
            "location": "/algorithm/pca/", 
            "text": "", 
            "title": "Principal Component Analysis"
        }, 
        {
            "location": "/algorithm/kmeans/", 
            "text": "", 
            "title": "K-means Clustering"
        }, 
        {
            "location": "/algorithm/encoder/", 
            "text": "", 
            "title": "Auto-encoder"
        }, 
        {
            "location": "/algorithm/compressive/", 
            "text": "", 
            "title": "Compressive Sensing"
        }, 
        {
            "location": "/algorithm/semi/", 
            "text": "", 
            "title": "Overview"
        }, 
        {
            "location": "/algorithm/reinforcement/", 
            "text": "", 
            "title": "Overiew"
        }, 
        {
            "location": "/algorithm/qlearning/", 
            "text": "", 
            "title": "Q learning"
        }, 
        {
            "location": "/framework/", 
            "text": "Machine Learning Library and Framework\uff1a\n\n\n What is a Machine Learning Framework and why do we need it? \n\n\nMachine learning engineers are part of the engineering team who build the product and the algorithms, making sure that it works reliably, quickly, and at-scale. However, to implement a machine learning algorithm, we usually need to deal with:\n\n    +Large scale size of data\n    +Complex mathematical computation\n\nMachine Learning Frameworks and relative libraries help us deal with such issues and make the implementation much easier.\n\n\n\n Some Popular Machine Learning Framework: \n\n\n+Caffe\n    Caffe is a deep learning framework made with expression, speed, and modularity in mind. It is developed by the Berkeley Vision and Learning Center (BVLC) and by community contributors. Yangqing Jia created the project during his PhD at UC Berkeley. Caffe is released under the BSD 2-Clause license.  Models and optimization are defined by configuration without hard-coding \n user can switch between CPU and GPU. Speed makes Caffe perfect for research experiments and industry deployment. Caffe can process over 60M images per day with a single NVIDIA K40 GPU.\n    detailed information can be found on its official website:  https://caffe.berkeleyvision.org\n\n+Torch\n    Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation. The goal of Torch is to have maximum flexibility and speed in building your scientific algorithms while making the process extremely simple. Torch comes with a large ecosystem of community-driven packages in machine learning, computer vision, signal processing, parallel processing, image, video, audio and networking among others, and builds on top of the Lua community.\n    detailed information can be found on its official website:  https://torch.cn\n\n+Tensorflow\n    TensorFlow is an open source software library for numerical computation using data flow graphs. TensorFlow implements what are called data flow graphs, where batches of data (\u201ctensors\u201d) can be processed by a series of algorithms described by a graph. The movements of the data through the system are called \u201cflows\u201d \u2014 hence, the name. Graphs can be assembled with C++ or Python and can be processed on CPUs or GPUs.\n    detailed information can be found on its official website:  https://www.tensorflow.org", 
            "title": "Machine Learning Framework"
        }, 
        {
            "location": "/framework/#machine-learning-library-and-framework", 
            "text": "What is a Machine Learning Framework and why do we need it?   Machine learning engineers are part of the engineering team who build the product and the algorithms, making sure that it works reliably, quickly, and at-scale. However, to implement a machine learning algorithm, we usually need to deal with:\n\n    +Large scale size of data\n    +Complex mathematical computation\n\nMachine Learning Frameworks and relative libraries help us deal with such issues and make the implementation much easier.   Some Popular Machine Learning Framework:   +Caffe\n    Caffe is a deep learning framework made with expression, speed, and modularity in mind. It is developed by the Berkeley Vision and Learning Center (BVLC) and by community contributors. Yangqing Jia created the project during his PhD at UC Berkeley. Caffe is released under the BSD 2-Clause license.  Models and optimization are defined by configuration without hard-coding   user can switch between CPU and GPU. Speed makes Caffe perfect for research experiments and industry deployment. Caffe can process over 60M images per day with a single NVIDIA K40 GPU.\n    detailed information can be found on its official website:  https://caffe.berkeleyvision.org\n\n+Torch\n    Torch is a scientific computing framework with wide support for machine learning algorithms that puts GPUs first. It is easy to use and efficient, thanks to an easy and fast scripting language, LuaJIT, and an underlying C/CUDA implementation. The goal of Torch is to have maximum flexibility and speed in building your scientific algorithms while making the process extremely simple. Torch comes with a large ecosystem of community-driven packages in machine learning, computer vision, signal processing, parallel processing, image, video, audio and networking among others, and builds on top of the Lua community.\n    detailed information can be found on its official website:  https://torch.cn\n\n+Tensorflow\n    TensorFlow is an open source software library for numerical computation using data flow graphs. TensorFlow implements what are called data flow graphs, where batches of data (\u201ctensors\u201d) can be processed by a series of algorithms described by a graph. The movements of the data through the system are called \u201cflows\u201d \u2014 hence, the name. Graphs can be assembled with C++ or Python and can be processed on CPUs or GPUs.\n    detailed information can be found on its official website:  https://www.tensorflow.org", 
            "title": "Machine Learning Library and Framework\uff1a"
        }, 
        {
            "location": "/bigdata/", 
            "text": "", 
            "title": "Big Data"
        }
    ]
}